# -*- coding: utf-8 -*-
"""MenHealth_BERT_Topic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BSJZOVPuLVUD4Q7UtQ0hUffeda66eyYp

## Task Description
Mental Illness Detection with BERTopic

#### Install Dependencies and Restart Runtime
"""

!pip install -q transformers
!pip install -q simpletransformers`
!pip install -U imbalanced-learn`

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/'CS 7650'

"""# Getting Data"""

## Importing packages
import pandas as pd
import numpy as np
import json
import re

#Feching and storing the data

df = pd.read_excel('reddit_data.xlsx')

# Report the number of sentences.
print('Number of training sentences: {:,}\n'.format(df.shape[0]))

# Display 10 random rows from the data.
df.sample(10)

df['Title'] = df['Title'].fillna('')
df['Text'] = df['Text'].fillna('')
df['Full_Text'] = df['Title'] + ' ' + df['Text']
df['Full_Text'] = df['Full_Text'].astype(str)

df.head()

df_subset1 = df[['ID', 'Full_Text','Label']]
df_subset1 = df_subset1.rename(columns={'Full_Text' : 'text'})
label_mapping = {'none': 0, 'anxiety': 1, 'depression': 2, 'OCD': 3, 'ptsd': 4, 'schizophrenia': 5, 'bipolar': 6, 'anorexia': 7}
df_subset1['labels'] = df_subset1['Label'].map(label_mapping)
df_subset1 = df_subset1.drop(['Label'], axis=1)
df_subset1.head()

#Create a function to clean text in the datafrmae
def clean_text(text):

  # Remove emojis
  text = re.sub(r'[:;][\w\d-]*[:;]', '', text)

  # Remove emoticons
  text = re.sub(r'\([^\)]*\)', '', text)

  # Remove hyperlinks
  text = re.sub(r'https?://[^\s]+', '', text)

  # Remove punctuation
  text = re.sub(r'[^\w\s]', '', text)

  # Convert all text into lowercase
  text = text.lower()

  return text

df_subset1['text'] = df_subset1['text'].apply(clean_text)
df_subset1.sample(10)



# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install bertopic
# from umap import UMAP
# umap_model = UMAP(random_state=123)

from bertopic import BERTopic
topic_model = BERTopic(language="english", calculate_probabilities=True, verbose=True, umap_model=umap_model)
topic_df = df_subset1.copy()
topic_df.head()

topics, probs = topic_model.fit_transform(topic_df['text'])
freq = topic_model.get_topic_info()
freq.head(5)

dict_topic = pd.Series(freq.Name.values,index=freq.Topic).to_dict()
topic_df['topics'] = topics
topic_df['topic_label'] = topic_df['topics'].replace(dict_topic)
topic_df[0:10]

topic_df['text'] = topic_df['topic_label'].map(str) + ': ' + topic_df['text'].map(str)
topic_df = topic_df.drop(['topics', 'topic_label'], axis =1)
topic_df.head()



import sklearn
from sklearn.model_selection import train_test_split
train_df, test_df = train_test_split(topic_df, test_size=0.20, random_state=123)

train_df.head()

train_df.info()

pip install simpletransformers

print(train_df.dtypes)

"""# Training and Testing the Model"""

import os
train_args = {
    'reprocess_input_data': True,
    'overwrite_output_dir': True,
    'sliding_window': True,
    'max_seq_length': 256,
    'num_train_epochs': 3,
    'train_batch_size': 16,
    'fp16': True,
    'output_dir': '/outputs/',
}

#RoBERTa
from simpletransformers.classification import ClassificationModel
import pandas as pd
import logging
import sklearn

logging.basicConfig(level=logging.DEBUG)
transformers_logger = logging.getLogger('transformers')
transformers_logger.setLevel(logging.WARNING)

model = ClassificationModel('roberta', 'roberta-base', num_labels=8, args=train_args)

model.train_model(train_df)

# Evaluate the model in terms of accuracy score
result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.accuracy_score)
print(result)

#F1 Score
from sklearn.metrics import f1_score

def f1_macro(y_true, y_pred):
    return f1_score(y_true, y_pred, average='macro')

result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=f1_macro)
print(result)

#Precision and Recall
result, model_outputs, wrong_predictions = model.eval_model(test_df, acc=sklearn.metrics.precision_recall_fscore_support)
print(result)

"""# RoBERTa

"""

train_args = {
    'reprocess_input_data': True,
    'overwrite_output_dir': True,
    'sliding_window': True,
    'max_seq_length': 256,
    'num_train_epochs': 3,
    'train_batch_size': 16,
    'fp16': True,
    'output_dir': '/outputs/',
}

#BERT
from simpletransformers.classification import ClassificationModel
import pandas as pd
import logging
import sklearn

logging.basicConfig(level=logging.DEBUG)
transformers_logger = logging.getLogger('transformers')
transformers_logger.setLevel(logging.WARNING)

model2 = ClassificationModel('bert', 'bert-base-uncased', num_labels=8, args=train_args)

# Train the model, there is no development or validation set for this dataset
# https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping
model2.train_model(train_df)

# Evaluate the model in terms of accuracy score
result, model_outputs, wrong_predictions = model2.eval_model(test_df, acc=sklearn.metrics.accuracy_score)
print(result)

#F1 Score
from sklearn.metrics import f1_score

def f1_macro(y_true, y_pred):
    return f1_score(y_true, y_pred, average='macro')

result, model_outputs, wrong_predictions = model2.eval_model(test_df, acc=f1_macro)
print(result)

#Precision and Recall
result, model_outputs, wrong_predictions = model2.eval_model(test_df, acc=sklearn.metrics.precision_recall_fscore_support)
print(result)